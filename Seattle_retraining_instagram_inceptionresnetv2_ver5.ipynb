{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5yspNM6GxBe0",
    "colab_type": "code",
    "outputId": "a7a91632-3a1b-4523-d33e-cc2b4f928786",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.549050404919E12,
     "user_tz": 480.0,
     "elapsed": 2265.0,
     "user": {
      "displayName": "Bumsuk Seo",
      "photoUrl": "",
      "userId": "16581242694089286841"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import fnmatch\n",
    "\n",
    "\n",
    "\n",
    "import ssl\n",
    "\n",
    "### To avoid certificat error (source: https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error)\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()\n",
    "\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "    pass\n",
    "else:\n",
    "    # Handle target environment that doesn't support HTTPS verification\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "\n",
    "from keras.applications import inception_resnet_v2\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import vgg16\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-bt8FiIuxmDt",
    "colab_type": "code",
    "outputId": "ea893e17-6c75-4d63-dca4-50dc19a87e4b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.549050693117E12,
     "user_tz": 480.0,
     "elapsed": 21913.0,
     "user": {
      "displayName": "Bumsuk Seo",
      "photoUrl": "",
      "userId": "16581242694089286841"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/googledrive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!mkdir -p googledrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/googledrive')\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "388kXjb5xoKX",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "default_path = '/content/googledrive/My Drive/FlickrCNN'\n",
    "os.chdir(default_path)\n",
    "photo_path = default_path + '/Photos_338_retraining'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "BvRBHGtfyFkJ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "from keras.applications import inception_resnet_v2\n",
    "\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "img_width, img_height = 331, 331\n",
    "train_data_dir = \"Photos_338_retraining/train\"\n",
    "validation_data_dir = \"Photos_338_retraining/validation\"\n",
    "nb_train_samples = 210\n",
    "nb_validation_samples = 99\n",
    "\n",
    "batch_size = 32 # proportional to the training sample size..\n",
    "epochs = 50\n",
    "\n",
    "num_classes = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NtKbKHFqyLta",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    },
    "outputId": "4194a30f-4936-4106-9d24-24a5c2b7c726",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.549050767899E12,
     "user_tz": 480.0,
     "elapsed": 43918.0,
     "user": {
      "displayName": "Bumsuk Seo",
      "photoUrl": "",
      "userId": "16581242694089286841"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "##### build our classifier model based on pre-trained InceptionResNetV2:\n",
    "\n",
    "# Load the base pre-trained model\n",
    "\n",
    "# do not include the top fully-connected layer\n",
    "# 1. we don't include the top (fully connected) layers of InceptionResNetV2\n",
    "\n",
    "model = inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet',input_tensor=None, input_shape=(img_width, img_height, 3))\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the all layers.\n",
    "# i.e. freeze all InceptionV3 layers\n",
    "for layer in model.layers[:]:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "uAnPoB1pyR-e",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "# New dataset is small and similar to original dataset:\n",
    "# There is a problem of over-fitting, if we try to train the entire network. Since the data is similar to the original data, we expect higher-level features in the ConvNet to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN codes.\n",
    "# So lets freeze all the layers and train only the classifier\n",
    "\n",
    "# first: train only the top layers\n",
    "\n",
    "# for layer in net_final.layers[:FREEZE_LAYERS]:\n",
    "#     layer.trainable = False\n",
    "# for layer in net_final.layers[FREEZE_LAYERS:]:\n",
    "#     layer.trainable = True\n",
    "\n",
    "\n",
    "x = model.output\n",
    "\n",
    "# Now that we have set the trainable parameters of our base network, we would like to add a classifier on top of the convolutional base. We will simply add a fully connected layer followed by a softmax layer with num_classes outputs.\n",
    "\n",
    "# Adding custom Layer\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "# 2. we add a DropOut layer followed by a Dense (fully connected)\n",
    "#    layer which generates softmax class score for each class\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax', name='softmax')(x)\n",
    "\n",
    " \n",
    "\n",
    "# creating the final model\n",
    "# this is the model we will train\n",
    "model_final = Model(inputs = model.input, outputs = predictions)\n",
    "\n",
    "\n",
    "#Now we will be training only the classifiers (FC layers)\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "\n",
    "# model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "\n",
    "# model_final.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "# model.compile(loss='sparse_categorical_crossentropy',\n",
    "#               optimizer=Adam(lr=0.0001),\n",
    "#               metrics=['acc'])\n",
    "\n",
    "# Compile the final model using an Adam optimizer, with a low learning rate (since we are 'fine-tuning')\n",
    "model_final.compile(optimizer=Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# print(model_final.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "eoG3wq7YyVff",
    "colab_type": "code",
    "outputId": "e8e4df21-40cd-486d-e7b1-3733b2cb02e9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.549050796821E12,
     "user_tz": 480.0,
     "elapsed": 2242.0,
     "user": {
      "displayName": "Bumsuk Seo",
      "photoUrl": "",
      "userId": "16581242694089286841"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 images belonging to 4 classes.\n",
      "Found 99 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initiate the train and test generators with data Augumentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range=0.3,\n",
    "    rotation_range=30)\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = \"nearest\",\n",
    "    zoom_range = 0.3,\n",
    "    width_shift_range = 0.3,\n",
    "    height_shift_range=0.3,\n",
    "    rotation_range=30)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = \"categorical\")\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    class_mode = \"categorical\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ek1E73oaGGSi",
    "colab_type": "code",
    "outputId": "554d2e48-29e6-4610-8998-d87bfe94621e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.549050800879E12,
     "user_tz": 480.0,
     "elapsed": 250.0,
     "user": {
      "displayName": "Bumsuk Seo",
      "photoUrl": "",
      "userId": "16581242694089286841"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************\n",
      "Class #0 = backpacking\n",
      "Class #1 = hiking\n",
      "Class #2 = hotsprings\n",
      "Class #3 = noactivity\n",
      "****************\n"
     ]
    }
   ],
   "source": [
    "# show class indices\n",
    "print('****************')\n",
    "for cls, idx in train_generator.class_indices.items():\n",
    "    print('Class #{} = {}'.format(idx, cls))\n",
    "print('****************')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "czUd7-Piaewe",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Save the model according to the conditions\n",
    "checkpoint = ModelCheckpoint(\"InceptionResnetV2_retrain.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=5)\n",
    "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "D1S1xwQjyZOr",
    "colab_type": "code",
    "outputId": "4e9d5545-257a-4139-c5a6-3133864e3535",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.549037850369E12,
     "user_tz": 480.0,
     "elapsed": 1272.0,
     "user": {
      "displayName": "Bumsuk Seo",
      "photoUrl": "",
      "userId": "16581242694089286841"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  4/210 [..............................] - ETA: 2:16:13 - loss: 1.8925 - acc: 0.3083"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Re-train the model\n",
    "history = model_final.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples,\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples,\n",
    "    callbacks = [checkpoint, early])\n",
    "\n",
    "# at this point, the top layers are well trained.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "evajellh2Oa4",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# at this point, the top layers are well trained.\n",
    "# Let's save the model\n",
    "model_final.save('InceptionResnetV2_retrain_instagram_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Js56An_7y8gG",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "E68WvPdK2P0-",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Get the filenames from the generator\n",
    "fnames = validation_generator.filenames\n",
    " \n",
    "# Get the ground truth from generator\n",
    "ground_truth = validation_generator.classes\n",
    " \n",
    "# Get the label to class mapping from the generator\n",
    "label2index = validation_generator.class_indices\n",
    " \n",
    "# Getting the mapping from class index to class label\n",
    "idx2label = dict((v,k) for k,v in label2index.items())\n",
    " \n",
    "# Get the predictions from the model using the generator\n",
    "predictions = model.predict_generator(validation_generator, steps=validation_generator.samples/validation_generator.batch_size,verbose=1)\n",
    "predicted_classes = np.argmax(predictions,axis=1)\n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "x-R8VZzC3q2E",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "errors = np.where(np.not_equal(predicted_classes, ground_truth[0]))\n",
    "print(\"No of errors = {}/{}\".format(len(errors),validation_generator.samples))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "qsBUO9iARDsH",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "# Show the errors\n",
    "for i in range(len(errors)):\n",
    "    pred_class = np.argmax(predictions[errors[i]])\n",
    "    pred_label = idx2label[pred_class]\n",
    "     \n",
    "    title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
    "        fnames[errors[i]].split('/')[0],\n",
    "        pred_label,\n",
    "        predictions[errors[i]][pred_class])\n",
    "     \n",
    "    original = load_img('{}/{}'.format(validation_data_dir,fnames[errors[i]]))\n",
    "    plt.figure(figsize=[7,7])\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.imshow(original)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Seattle_retraining_instagram_v5.ipynb",
   "version": "0.3.2",
   "provenance": [
    {
     "file_id": "1oLQDIyni3ChntMNaN2w-CT_Wn-Jkp9LN",
     "timestamp": 1.549038332175E12
    }
   ],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
