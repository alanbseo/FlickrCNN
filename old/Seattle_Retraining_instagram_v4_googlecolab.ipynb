{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Seattle_retraining_instagram.ipynb","version":"0.3.2","provenance":[{"file_id":"1oLQDIyni3ChntMNaN2w-CT_Wn-Jkp9LN","timestamp":1549028088289}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"5yspNM6GxBe0","colab_type":"code","outputId":"4b28f914-255e-4861-e431-363b92c43581","executionInfo":{"status":"ok","timestamp":1549024507546,"user_tz":480,"elapsed":2118,"user":{"displayName":"Bumsuk Seo","photoUrl":"","userId":"16581242694089286841"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["\n","import keras\n","import numpy as np\n","import os\n","import cv2\n","\n","import csv\n","import pandas as pd\n","import pathlib\n","import fnmatch\n","\n","\n","\n","import ssl\n","\n","### Avoid certificat error (source: https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error)\n","import requests\n","requests.packages.urllib3.disable_warnings()\n","\n","import ssl\n","\n","try:\n","    _create_unverified_https_context = ssl._create_unverified_context\n","except AttributeError:\n","    # Legacy Python that doesn't verify HTTPS certificates by default\n","    pass\n","else:\n","    # Handle target environment that doesn't support HTTPS verification\n","    ssl._create_default_https_context = _create_unverified_https_context\n","\n","\n","from keras.applications import inception_resnet_v2\n","from keras.preprocessing.image import load_img\n","from keras.preprocessing.image import img_to_array\n","from keras.applications.imagenet_utils import decode_predictions\n","import matplotlib.pyplot as plt\n","\n","\n","\n","from keras.preprocessing import image\n","from keras.applications import vgg16\n","import numpy as np\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"-bt8FiIuxmDt","colab_type":"code","outputId":"8b330b19-03e6-4bae-a43a-5a323512a895","executionInfo":{"status":"ok","timestamp":1549024570141,"user_tz":480,"elapsed":64699,"user":{"displayName":"Bumsuk Seo","photoUrl":"","userId":"16581242694089286841"}},"colab":{"base_uri":"https://localhost:8080/","height":171}},"cell_type":"code","source":["\n","!mkdir -p googledrive\n","from google.colab import drive\n","drive.mount('/content/googledrive')\n"," \n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/googledrive\n"],"name":"stdout"}]},{"metadata":{"id":"388kXjb5xoKX","colab_type":"code","colab":{}},"cell_type":"code","source":["default_path = '/content/googledrive/My Drive/FlickrCNN'\n","os.chdir(default_path)\n","photo_path = default_path + '/Photos_338_retraining'\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BvRBHGtfyFkJ","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.applications import inception_resnet_v2\n","\n","\n","from keras import applications\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from keras.optimizers import Adam\n","\n","from keras.models import Sequential, Model\n","from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n","from keras import backend as k\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n","img_width, img_height = 331, 331\n","train_data_dir = \"Photos_338_retraining/train\"\n","validation_data_dir = \"Photos_338_retraining/validation\"\n","nb_train_samples = 210\n","nb_validation_samples = 99\n","\n","batch_size = 16 # proportional to the training sample size..\n","epochs = 50\n","\n","num_classes = 4\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NtKbKHFqyLta","colab_type":"code","colab":{}},"cell_type":"code","source":["##### build our classifier model based on pre-trained InceptionResNetV2:\n","\n","# Load the base pre-trained model\n","\n","# do not include the top fully-connected layer\n","# 1. we don't include the top (fully connected) layers of InceptionResNetV2\n","\n","model = inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet',input_tensor=None, input_shape=(img_width, img_height, 3))\n","# Freeze the layers which you don't want to train. Here I am freezing the all layers.\n","# i.e. freeze all InceptionV3 layers\n","for layer in model.layers[:]:\n","    layer.trainable = False\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uAnPoB1pyR-e","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# New dataset is small and similar to original dataset:\n","# There is a problem of over-fitting, if we try to train the entire network. Since the data is similar to the original data, we expect higher-level features in the ConvNet to be relevant to this dataset as well. Hence, the best idea might be to train a linear classifier on the CNN codes.\n","# So lets freeze all the layers and train only the classifier\n","\n","# first: train only the top layers\n","\n","# for layer in net_final.layers[:FREEZE_LAYERS]:\n","#     layer.trainable = False\n","# for layer in net_final.layers[FREEZE_LAYERS:]:\n","#     layer.trainable = True\n","\n","\n","x = model.output\n","\n","# Now that we have set the trainable parameters of our base network, we would like to add a classifier on top of the convolutional base. We will simply add a fully connected layer followed by a softmax layer with num_classes outputs.\n","\n","# Adding custom Layer\n","x = Flatten()(x)\n","x = Dense(1024, activation='relu')(x)\n","\n","# 2. we add a DropOut layer followed by a Dense (fully connected)\n","#    layer which generates softmax class score for each class\n","x = Dropout(0.5)(x)\n","predictions = Dense(num_classes, activation='softmax', name='softmax')(x)\n","\n","\n","\n","# creating the final model\n","# this is the model we will train\n","model_final = Model(inputs = model.input, outputs = predictions)\n","\n","\n","#Now we will be training only the classifiers (FC layers)\n","\n","# compile the model (should be done *after* setting layers to non-trainable)\n","\n","# model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n","\n","# model_final.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n","# model.compile(loss='sparse_categorical_crossentropy',\n","#               optimizer=Adam(lr=0.0001),\n","#               metrics=['acc'])\n","\n","# Compile the final model using an Adam optimizer, with a low learning rate (since we are 'fine-tuning')\n","model_final.compile(optimizer=Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n","print(model_final.summary())\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eoG3wq7YyVff","colab_type":"code","outputId":"480aafcf-4b51-4906-92c8-234fcb9d59d4","executionInfo":{"status":"ok","timestamp":1549024620709,"user_tz":480,"elapsed":115213,"user":{"displayName":"Bumsuk Seo","photoUrl":"","userId":"16581242694089286841"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["\n","\n","# Initiate the train and test generators with data Augumentation\n","train_datagen = ImageDataGenerator(\n","    rescale = 1./255,\n","    horizontal_flip = True,\n","    fill_mode = \"nearest\",\n","    zoom_range = 0.3,\n","    width_shift_range = 0.3,\n","    height_shift_range=0.3,\n","    rotation_range=30)\n","test_datagen = ImageDataGenerator(\n","    rescale = 1./255,\n","    horizontal_flip = True,\n","    fill_mode = \"nearest\",\n","    zoom_range = 0.3,\n","    width_shift_range = 0.3,\n","    height_shift_range=0.3,\n","    rotation_range=30)\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size = (img_height, img_width),\n","    batch_size = batch_size,\n","    class_mode = \"categorical\")\n","validation_generator = test_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size = (img_height, img_width),\n","    class_mode = \"categorical\")\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 210 images belonging to 4 classes.\n","Found 99 images belonging to 4 classes.\n"],"name":"stdout"}]},{"metadata":{"id":"ek1E73oaGGSi","colab_type":"code","colab":{}},"cell_type":"code","source":["# show class indices\n","print('****************')\n","for cls, idx in train_generator.class_indices.items():\n","    print('Class #{} = {}'.format(idx, cls))\n","print('****************')\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"czUd7-Piaewe","colab_type":"code","colab":{}},"cell_type":"code","source":["# Save the model according to the conditions\n","checkpoint = ModelCheckpoint(\"InceptionResnetV2_retrain.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D1S1xwQjyZOr","colab_type":"code","outputId":"b68303ec-269c-4d96-eedd-826d99fe2bdf","colab":{"base_uri":"https://localhost:8080/","height":595}},"cell_type":"code","source":["\n","\n","# Re-train the model\n","history = model_final.fit_generator(\n","    train_generator,\n","    steps_per_epoch = nb_train_samples,\n","    epochs = epochs,\n","    validation_data = validation_generator,\n","    validation_steps = nb_validation_samples,\n","    callbacks = [checkpoint, early])\n","\n","# at this point, the top layers are well trained.\n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","210/210 [==============================] - 493s 2s/step - loss: 1.3452 - acc: 0.4363 - val_loss: 1.2050 - val_acc: 0.5659\n","\n","Epoch 00001: val_acc improved from -inf to 0.56594, saving model to InceptionResnetV2_retrain.h5\n","Epoch 2/50\n","210/210 [==============================] - 389s 2s/step - loss: 0.9915 - acc: 0.5950 - val_loss: 1.0360 - val_acc: 0.5911\n","\n","Epoch 00002: val_acc improved from 0.56594 to 0.59108, saving model to InceptionResnetV2_retrain.h5\n","Epoch 3/50\n","210/210 [==============================] - 400s 2s/step - loss: 0.8425 - acc: 0.6730 - val_loss: 1.0827 - val_acc: 0.6160\n","\n","Epoch 00003: val_acc improved from 0.59108 to 0.61605, saving model to InceptionResnetV2_retrain.h5\n","Epoch 4/50\n","210/210 [==============================] - 399s 2s/step - loss: 0.6915 - acc: 0.7390 - val_loss: 1.1380 - val_acc: 0.6238\n","\n","Epoch 00004: val_acc improved from 0.61605 to 0.62382, saving model to InceptionResnetV2_retrain.h5\n","Epoch 5/50\n","210/210 [==============================] - 402s 2s/step - loss: 0.6716 - acc: 0.7370 - val_loss: 1.1831 - val_acc: 0.6210\n","\n","Epoch 00005: val_acc did not improve from 0.62382\n","Epoch 6/50\n","210/210 [==============================] - 402s 2s/step - loss: 0.6127 - acc: 0.7578 - val_loss: 1.3731 - val_acc: 0.5841\n","\n","Epoch 00006: val_acc did not improve from 0.62382\n","Epoch 7/50\n","210/210 [==============================] - 405s 2s/step - loss: 0.5390 - acc: 0.7905 - val_loss: 1.2591 - val_acc: 0.6267\n","\n","Epoch 00007: val_acc improved from 0.62382 to 0.62669, saving model to InceptionResnetV2_retrain.h5\n","Epoch 8/50\n","210/210 [==============================] - 403s 2s/step - loss: 0.5710 - acc: 0.7784 - val_loss: 1.4024 - val_acc: 0.6181\n","\n","Epoch 00008: val_acc did not improve from 0.62669\n","Epoch 9/50\n"," 25/210 [==>...........................] - ETA: 3:05 - loss: 0.4543 - acc: 0.8325"],"name":"stdout"}]},{"metadata":{"id":"evajellh2Oa4","colab_type":"code","colab":{}},"cell_type":"code","source":["# at this point, the top layers are well trained.\n","# Let's save the model\n","model_final.save('Seattle_Instagram.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Js56An_7y8gG","colab_type":"code","colab":{}},"cell_type":"code","source":[" \n","\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs, acc, 'b', label='Training acc')\n","plt.plot(epochs, val_acc, 'r', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'b', label='Training loss')\n","plt.plot(epochs, val_loss, 'r', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E68WvPdK2P0-","colab_type":"code","colab":{}},"cell_type":"code","source":["# Get the filenames from the generator\n","fnames = validation_generator.filenames\n"," \n","# Get the ground truth from generator\n","ground_truth = validation_generator.classes\n"," \n","# Get the label to class mapping from the generator\n","label2index = validation_generator.class_indices\n"," \n","# Getting the mapping from class index to class label\n","idx2label = dict((v,k) for k,v in label2index.items())\n"," \n","# Get the predictions from the model using the generator\n","predictions = model.predict_generator(validation_generator, steps=validation_generator.samples/validation_generator.batch_size,verbose=1)\n","predicted_classes = np.argmax(predictions,axis=1)\n"," \n","errors = np.where(predicted_classes != ground_truth)[0]\n","print(\"No of errors = {}/{}\".format(len(errors),validation_generator.samples))\n"," "],"execution_count":0,"outputs":[]},{"metadata":{"id":"qsBUO9iARDsH","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# Show the errors\n","for i in range(len(errors)):\n","    pred_class = np.argmax(predictions[errors[i]])\n","    pred_label = idx2label[pred_class]\n","     \n","    title = 'Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n","        fnames[errors[i]].split('/')[0],\n","        pred_label,\n","        predictions[errors[i]][pred_class])\n","     \n","    original = load_img('{}/{}'.format(validation_data_dir,fnames[errors[i]]))\n","    plt.figure(figsize=[7,7])\n","    plt.axis('off')\n","    plt.title(title)\n","    plt.imshow(original)\n","    plt.show()"],"execution_count":0,"outputs":[]}]}